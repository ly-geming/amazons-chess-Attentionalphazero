import torch
import torch.nn.functional as F
import numpy as np
import multiprocessing as mp
import queue
import time
import logging
import traceback 
import sys
import os
import psutil

log = logging.getLogger(__name__)

# =============================================================================
# [æ ¸å¿ƒ] C++ æ¨¡å—åŠ è½½ä¸æ—¥å¿—æ£€æµ‹
# =============================================================================
print("\n" + "="*60)
print("[GpuWorker] æ­£åœ¨åˆå§‹åŒ–ç‰¹å¾æå–æ¨¡å—...")

try:
    import amazons_ops
    CPP_FEATURE_AVAILABLE = True
    
    # è·å–æ¨¡å—æ–‡ä»¶è·¯å¾„ï¼ˆç¡®è®¤åŠ è½½çš„æ˜¯å“ªä¸€ä¸ªæ–‡ä»¶ï¼‰
    module_path = getattr(amazons_ops, '__file__', 'Unknown location')
    
    print(f"[GpuWorker] âœ… C++ Extension åŠ è½½æˆåŠŸ!")
    print(f"[GpuWorker] ğŸ“ æ¨¡å—è·¯å¾„: {module_path}")
    print("[GpuWorker] ğŸš€ æ¨¡å¼: é«˜æ€§èƒ½ C++ ç‰¹å¾æå– (ä¸è’¸é¦è®­ç»ƒä¿æŒ 100% ä¸€è‡´)")

except ImportError as e:
    CPP_FEATURE_AVAILABLE = False
    print(f"[GpuWorker] âŒ C++ Extension åŠ è½½å¤±è´¥!")
    print(f"[GpuWorker] âš ï¸ é”™è¯¯ä¿¡æ¯: {e}")
    print("[GpuWorker] ğŸ¢ æ¨¡å¼: Python æ…¢é€Ÿå…¼å®¹æ¨¡å¼ (è­¦å‘Šï¼šå¦‚é€»è¾‘ä¸ä¸€è‡´ä¼šå¯¼è‡´æ¦‚ç‡å¼‚å¸¸)")
    
print("="*60 + "\n")

def set_high_priority():
    try:
        p = psutil.Process(os.getpid())
        if os.name == 'nt': p.nice(psutil.HIGH_PRIORITY_CLASS)
        else: p.nice(-10)
    except Exception: pass

# =============================================================================
# Python å›é€€é€»è¾‘ (ä»…å½“ C++ åŠ è½½å¤±è´¥æ—¶ä½¿ç”¨)
# =============================================================================
def get_mobility_batch_python(pcs, obs):
    B, H, W = pcs.shape
    mob = np.zeros((B, H, W), dtype=np.float32)
    dirs = [(0,1), (0,-1), (1,0), (-1,0), (1,1), (1,-1), (-1,1), (-1,-1)]
    for i in range(B):
        p_locs = np.argwhere(pcs[i] > 0)
        for r, c in p_locs:
            for dr, dc in dirs:
                cr, cc = r+dr, c+dc
                while 0 <= cr < 8 and 0 <= cc < 8:
                    if obs[i, cr, cc] != 0: break
                    mob[i, cr, cc] = 1.0
                    cr += dr
                    cc += dc
    return mob

def get_7ch_features_batch_python(board_3ch):
    B = board_3ch.shape[0]
    my_map = board_3ch[:, 0]
    op_map = board_3ch[:, 1]
    obstacles = (my_map + op_map + board_3ch[:, 2]) > 0.5
    obstacles = obstacles.astype(np.float32)

    my_mob = get_mobility_batch_python(my_map, obstacles)
    op_mob = get_mobility_batch_python(op_map, obstacles)
    my_pot = get_mobility_batch_python(my_mob, obstacles)
    op_pot = get_mobility_batch_python(op_mob, obstacles)

    # å †å é¡ºåºå¿…é¡»ä¸ C++ write_board_to_numpy ä¿æŒä¸€è‡´
    res = np.stack([my_map, op_map, obstacles, my_mob, op_mob, my_pot, op_pot], axis=1)
    return res

# =============================================================================
# æ··åˆç‰¹å¾æå–å™¨
# =============================================================================

def get_7ch_features_batch(board_3ch):
    """
    æ™ºèƒ½é€‰æ‹© C++ æˆ– Python è¿›è¡Œç‰¹å¾è®¡ç®—
    """
    if CPP_FEATURE_AVAILABLE:
        try:
            B = board_3ch.shape[0]
            board_7ch = np.zeros((B, 7, 8, 8), dtype=np.float32)
            
            # C++ æ¥å£ç›®å‰åªæ”¯æŒå•æ¿è¾“å…¥ï¼Œå¾ªç¯è°ƒç”¨ C++ å‡½æ•°
            # ç”±äº C++ å†…éƒ¨ä½è¿ç®—æå¿«ï¼Œè¿™é€šå¸¸æ¯” Python æ‰¹å¤„ç†è¿˜è¦å¿«
            for i in range(B):
                my = board_3ch[i, 0].astype(np.int32)
                op = board_3ch[i, 1].astype(np.int32)
                arr = board_3ch[i, 2].astype(np.int32)
                
                board_7ch[i] = amazons_ops.compute_7ch_features(my, op, arr)
            
            return board_7ch
        except Exception as e:
            print(f"[GpuWorker] âš ï¸ C++ Execution Error: {e}. Falling back to Python once.")
            return get_7ch_features_batch_python(board_3ch)
    else:
        return get_7ch_features_batch_python(board_3ch)

def encode_batch_one_hot(boards_numpy):
    """Step 1: åŸºç¡€ 3 é€šé“ç¼–ç  (My, Op, Arrow)"""
    if not isinstance(boards_numpy, np.ndarray):
        boards_numpy = np.array(boards_numpy)
    layer_my = (boards_numpy == 1).astype(np.float32)
    layer_op = (boards_numpy == -1).astype(np.float32)
    # 0=Empty, 1=My, -1=Op. ä»»ä½•éè¿™ä¸‰ä¸ªå€¼çš„éƒ½è¢«è§†ä¸º Arrow (é€šå¸¸æ˜¯ 2)
    layer_arr = (~np.isin(boards_numpy, [0, 1, -1])).astype(np.float32)
    return np.stack([layer_my, layer_op, layer_arr], axis=1)

# =============================================================================
# Worker Class
# =============================================================================

class GpuWorker:
    def __init__(self, game_class_name, game_params, network_class_name, network_params, args_dict):
        if game_class_name == "AmazonsGame":
            from amazons.AmazonsGame import AmazonsGame as GameClass
        else: raise ValueError(f"Unknown game class: {game_class_name}")

        if network_class_name == "NNetWrapper":
            from amazons.pytorch.NNet import NNetWrapper as NetworkClass
        else: raise ValueError(f"Unknown network class: {network_class_name}")

        class ArgsObj:
            def __init__(self, d):
                for k, v in d.items(): setattr(self, k, v)

        args = ArgsObj(args_dict)
        self.game = GameClass(**game_params)
        self.nnet = NetworkClass(self.game, args)

        if 'model_path' in network_params:
            try:
                full_path = os.path.join(network_params['checkpoint'], network_params['filename'])
                print(f"[GpuWorker] ğŸ“¥ æ­£åœ¨åŠ è½½æ¨¡å‹æƒé‡: {full_path}")
                
                if not os.path.exists(full_path):
                    print(f"[GpuWorker] âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨! GpuWorker å°†é€€å‡ºã€‚è¯·æ£€æŸ¥ checkpoint è·¯å¾„ã€‚")
                    sys.exit(1)
                    
                self.nnet.load_checkpoint(network_params['checkpoint'], network_params['filename'])
                print(f"[GpuWorker] âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸã€‚")
            except Exception as e:
                log.error(f"GPU Worker load model failed: {e}")
                sys.exit(1)

        self.nnet.nnet.eval()
        self.nnet.nnet.to(self.nnet.device)
        print(f"[GpuWorker] Started on Device: {self.nnet.device}")

    def run(self, gpu_work_queue, gpu_result_queues_list):
        set_high_priority()
        
        try:
            while True:
                try:
                    # 1. è·å–ä»»åŠ¡
                    boards_numpy, dispatcher_id = gpu_work_queue.get(timeout=2.0)

                    # 2. é¢„å¤„ç†: 3ch -> 7ch (C++)
                    boards_3ch = encode_batch_one_hot(boards_numpy)
                    boards_7ch = get_7ch_features_batch(boards_3ch)
                    
                    boards_tensor = torch.from_numpy(boards_7ch).float().to(self.nnet.device)

                    # 3. æ¨ç† (Model B)
                    with torch.no_grad():
                        # Model B forward returns: log_p_move, log_p_arrow, v
                        # log_p_move: (B, 4096) - LogSoftmaxed
                        # log_p_arrow: (B, 4096, 64) - LogSoftmaxed
                        # v: (B, 1)
                        
                        log_p_move, log_p_arrow, v = self.nnet.nnet(boards_tensor)
                        
                        # è½¬ä¸ºæ¦‚ç‡ (Exp) ä¾› MCTS ä½¿ç”¨
                        # æ³¨æ„ï¼šp_arrow çŸ©é˜µå¾ˆå¤§ (B * 4096 * 64)ï¼Œä¼ è¾“å¯èƒ½ä¼šæˆä¸ºç“¶é¢ˆ
                        # å¦‚æœ IPC å¡é¡¿ï¼Œåç»­å¯åœ¨ MCTS ç«¯æ¥æ”¶ Logitsï¼Œæˆ–è€…åœ¨è¿™é‡Œåªä¼  Top-K
                        p_move = torch.exp(log_p_move).data.cpu().numpy()
                        p_arrow = torch.exp(log_p_arrow).data.cpu().numpy()
                        vs = v.data.cpu().numpy()
                        
                    # 4. å‘é€ç»“æœ
                    if 0 <= dispatcher_id < len(gpu_result_queues_list):
                        # ç»“æ„: ((p_move, p_arrow), vs)
                        gpu_result_queues_list[dispatcher_id].put(((p_move, p_arrow), vs.astype(np.float64)))
                    
                except queue.Empty:
                    continue
        
        except Exception as e:
            print(f"\n!!! GPU WORKER CRASHED !!! Error: {e}", flush=True)
            traceback.print_exc()
            sys.exit(1) 

def gpu_worker_process_main(gpu_work_queue, gpu_result_queues_list, args_dict, game_class_name, game_params, network_class_name, network_params):
    worker = GpuWorker(game_class_name, game_params, network_class_name, network_params, args_dict)
    worker.run(gpu_work_queue, gpu_result_queues_list)

def start_gpu_worker_process(gpu_work_queue, gpu_result_queues_list, args_obj, game_class_name, game_params, network_class_name, network_params):
    args_dict = {}
    for attr in dir(args_obj):
        if not attr.startswith('_') and not callable(getattr(args_obj, attr)):
            try:
                val = getattr(args_obj, attr)
                if isinstance(val, (str, int, float, bool, list, dict, tuple)) or val is None:
                    args_dict[attr] = val
            except: pass

    gpu_worker_proc = mp.Process(
        target=gpu_worker_process_main,
        args=(gpu_work_queue, gpu_result_queues_list, args_dict, game_class_name, game_params, network_class_name, network_params)
    )
    gpu_worker_proc.start()
    return gpu_worker_proc